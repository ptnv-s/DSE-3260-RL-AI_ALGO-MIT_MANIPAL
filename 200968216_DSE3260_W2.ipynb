{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DSE 3260\n",
        "## Week - 2\n",
        "### Reg. No - 200968216\n",
        "#### Pratinav Seth "
      ],
      "metadata": {
        "id": "pY0Jj0JE1Kyi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Take the TF-Agents Environments Tutorial: \n",
        "\n",
        "https://colab.research.google.com/github/tensorflow/agents/blob/master/docs/tutorials/2_environments_tutorial.ipynb"
      ],
      "metadata": {
        "id": "hwM7Yk781b3e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use the CartPole-v0 environment and write a program to\n"
      ],
      "metadata": {
        "id": "fxYHmcrh4W9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf-agents[reverb]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcf4kOrhDymf",
        "outputId": "f5db9e86-f648-4895-c5b7-4600204132bb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tf-agents[reverb] in /usr/local/lib/python3.8/dist-packages (0.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (1.15.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (4.5.0)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (2.2.1)\n",
            "Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (3.19.6)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-probability>=0.18.0 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (0.19.0)\n",
            "Requirement already satisfied: gym<=0.23.0,>=0.17.0 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (0.23.0)\n",
            "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (1.21.6)\n",
            "Requirement already satisfied: pygame==2.1.0 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (2.1.0)\n",
            "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (0.5.0)\n",
            "Requirement already satisfied: rlds in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (0.1.7)\n",
            "Requirement already satisfied: tensorflow==2.11.0 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (2.11.0)\n",
            "Requirement already satisfied: dm-reverb~=0.10.0 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (0.10.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (15.0.6.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (2.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (3.1.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (2.11.2)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (23.1.21)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (0.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (0.30.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (0.4.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (2.11.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (23.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (2.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (57.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (1.51.1)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.8/dist-packages (from dm-reverb~=0.10.0->tf-agents[reverb]) (1.3.9)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from dm-reverb~=0.10.0->tf-agents[reverb]) (0.1.8)\n",
            "Requirement already satisfied: importlib-metadata>=4.10.0 in /usr/local/lib/python3.8/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (6.0.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (0.0.8)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability>=0.18.0->tf-agents[reverb]) (4.4.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow==2.11.0->tf-agents[reverb]) (0.38.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.10.0->gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (3.13.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (2.16.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (2.25.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (2.10)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.environments import suite_gym"
      ],
      "metadata": {
        "id": "rGhkJNqfEjBz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Implement the CartPole environment for a certain number of steps "
      ],
      "metadata": {
        "id": "98bBIZo15LHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enviornment = suite_gym.load('CartPole-v0')\n",
        "tf_enviornment = tf_py_environment.TFPyEnvironment(enviornment)\n",
        "\n",
        "time_step = tf_enviornment.reset()\n",
        "num_steps = 20\n",
        "transitions = []\n",
        "reward = 0\n",
        "for i in range(num_steps):\n",
        "  action = tf.constant([i % 2])\n",
        "  next_time_step = tf_enviornment.step(action)\n",
        "  transitions.append([time_step, action, next_time_step])\n",
        "  # adding reward\n",
        "  reward += next_time_step.reward\n",
        "  time_step = next_time_step\n",
        "print(f'Total reward: {reward.numpy()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzDoSmP3FYef",
        "outputId": "f2bbc42b-b34c-454a-d100-0df1622b441c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total reward: [20.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Implement the CartPole environment for a certain number of episodes"
      ],
      "metadata": {
        "id": "-KtCPOHf5Qgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enviornment = suite_gym.load('CartPole-v0') \n",
        "tf_enviornment = tf_py_environment.TFPyEnvironment(enviornment) \n",
        "\n",
        "time_step = tf_enviornment.reset()\n",
        "rewards = []\n",
        "steps = []\n",
        "num_episodes = 5\n",
        "for _ in range(num_episodes):\n",
        "  episode_reward = 0\n",
        "  episode_steps = 0\n",
        "  while not time_step.is_last():\n",
        "    action = tf.constant([episode_steps % 2])\n",
        "    time_step = tf_enviornment.step(action)\n",
        "    episode_steps += 1\n",
        "    episode_reward += time_step.reward.numpy()\n",
        "  rewards.append(float(episode_reward))\n",
        "  steps.append(episode_steps)\n",
        "  time_step = tf_enviornment.reset()\n",
        "\n",
        "num_steps = np.sum(steps)\n",
        "avg_length = np.mean(steps)\n",
        "avg_reward = np.mean(rewards)\n",
        "\n",
        "print(f'steps: {steps}')\n",
        "print(f'rewards: {rewards}')\n",
        "print(f'num_episodes: {num_episodes}, num_steps: {num_steps}')\n",
        "print(f'avg_length: {avg_length}, avg_reward: {avg_reward}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0yRcdQuG9R3",
        "outputId": "5c598ea9-c5fb-4bdf-d7b4-2858b7778ca5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "steps: [50, 56, 26, 26, 39]\n",
            "rewards: [50.0, 56.0, 26.0, 26.0, 39.0]\n",
            "num_episodes: 5, num_steps: 197\n",
            "avg_length: 39.4, avg_reward: 39.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c. Compare and comment on the rewards earned for both approaches."
      ],
      "metadata": {
        "id": "DU2g2gp05VHF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For CartPole-v0 the end state is when the pole falls over.<br>\n",
        "Policy refers to the manner/ governing function which chooses which action should be taken next based on the current state.<br>\n",
        "<br>\n",
        "When we run for a certain (limited) amount of steps, we do not let the agent naturally reach the end stateas a result of the policy  chosen and terminate it's execution after the certain number of steps (in this case 20). This in itself will limit the amount of rewards that the agent can acheive on its own. As we can see the agent has achieved a reward of 20 which is the maximum it can acheive for 20 steps.<br>\n",
        "<br>\n",
        "However in the case of episodes, we allow the agent to naturally reach it's end state based on the policy chosen. As such it is able to gather more rewards (as long as it runs for more time steps than the previous approach). This can be seen from the printed lists where each of them are runnig more than 20 steps and the rewards themselves are more than 20. <br>\n",
        "<br>\n",
        "Since we have used the same policy for choosing action in both approaches, i.e., based on whether the step is the step number is even or odd, we can see that the average length or average number of steps with this policy is 27.2 and average reward is 27.2 which is greater than the 20 we obtained by running on a limited 20 steps in the first approach. <br>\n",
        "<br>\n",
        "There is no carry over of enviornment state from episode to episode as the enviornment is being reset using the given function before every episode, further supporting the above comparison.\n",
        "\n"
      ],
      "metadata": {
        "id": "mD8Gr20dQDPR"
      }
    }
  ]
}